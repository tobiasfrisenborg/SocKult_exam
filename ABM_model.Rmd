---
title: "Confidence in Joint Decision Making - A Simulation-Based Approach"
author: "Mie Arnau Martinez & Tobias Frisenborg Christensen"
date: "4/15/2020"
output: word_document
---

#  ABM Specifications and Parameters
## Properties of Agents
  - *Knowledge:* (Normal distribution, mu=100, sd=15)
    **https://www.mensa.org/iq/what-iq**
  - *Confidence Level:* (Percentage score e.g. 1.3 (overconfident) or 0.7 (unconfident))
      Scores on a scale (Very unconfident, slightly unconfident, neutral, slightly overconfident, very overconfident)
        ***#TODO: Read literature to find confidence scale - does it scale with/depend on skill?***
  - *Confidence:* (knowledge * confidence)
  - *Reputation:* Proportion of correct responses out of total responses

## Properties of Groups
  - *Decision:*
    - Baseline: Confidence is the only factor for the group decision function (equality bias)
      Weight of agent response is calculated as **confidence / sum(confidence)**
    - Reputation: All agents can assign weights to their group members answers, based on reputation, to mitigate the equality bias.
      Weight of agent response is calculated as ...
        ***#TODO: Define this decision function***
    - Confirmation: If other agents have the same response, the weight of that response is increased (confirmation bias).
      Weight of agent response is calculated as ...
        ***#TODO: Define this decision function***
  
## Updating of properties:
  - *Reputation:* Proportion of correct responses in percent
    Updated at the end of each round
  - **Self confidence is updated at each round as a function of correct answers (maybe include error)**
      ***#TODO: Do we need this?***

Experimental setup:
  - *Manipulated Variables*
    - Group decision function (baseline/equality, reputation, confirmation)
    - Confidence
    - Group composition in relation to proportion of over- and unconfident agents
  - *Environment:*
    - Influence of reputation and confirmation bias in multiple models, versus one baseline model (equality bias)
  - *Outcome:*
    - Performance of group (mean payoff over trials)
    - Performance of group (time to find correct solution)**
        ***#TODO: Do we need this?***

```{r Setup, include=FALSE}

library(pacman)
pacman::p_load(tidyverse)

set.seed(15)



# TODO: Investigate literature to define weights in groups decision making
# TODO: Investigate literature to define confidence values
# TODO: Define group compositions in terms of different confidence values
# TODO: Define the problem to solve, can it be made more complex so agents can be close or far off from the actual answer?

# define function for min-max scaling
MinMaxScaling <- function(x){
  return((x-min(x)) / (max(x)-  min(x)))
}


```



``` {r Setup Agent Attributes}

# define function for creating agents
create_agents <- function(group_size) {
  
  # setup number of groups and agents
  n_groups <- 50
  n_agents <- group_size * n_groups
  
  # create dataframe
  agents <- as.data.frame(seq(from = 1, to = n_agents))
  colnames(agents)[1] <- "agent_id"
  
  # define agents groups
  agents$group_id <- sort(rep(1:n_groups, group_size))
  
  # define group size column
  agents$group_size <- group_size
  
  # defining knowledge and calculate probabiltiy from it
  agents$knowledge <- round(rnorm(length(agents$agent_id), mean=100, sd=15))
  
  # TODO: Make sure this is a fair way of doing it (as min prob is approx 25% and max prob is approx 75%)
  #agents$knowledge_prob <- agents$knowledge / 200
  agents$knowledge_scaled <- MinMaxScaling(agents$knowledge)
  #agents$knowledge_scaled <- scale(agents$knowledge)
  
  # define confidence
  # TODO: Adjust these numbers according to literature to avoid arbitrary numbers
  #       It could take confidence bias into consideration, so that agents with
  #       higher knowledge are less confident and agents with less knowledge
  #       are more confident
  conf_vec <- c(0.5, 0.75, 1, 1.25, 1.5)
  
  # assign confidence randomly for each participant
  agents$conf_value <- NA
  
  for (i in 1:length(agents$agent_id)) {
    agents$conf_value[i] <- sample(conf_vec, 1) }
  
  # TODO: Should this be rounded?
  agents$confidence <- round(agents$knowledge * agents$conf_value)
  
  # convert confidence to probability
  agents <- agents %>%
    group_by(group_id) %>%
    mutate(conf_sum = sum(confidence))
  
  agents$conf_group_prob <- (agents$confidence / agents$conf_sum)
  
  # assign all agents the same baseline reputation
  agents$reputation <- 1
  
  return(agents)
}



group_size = 3

# create the agents
agent_attr <- create_agents(group_size)


```



``` {r Decision Functions}

# define function for calculating that probability is correct
agent_prob_adjust <- function(prob_agent, prob_error) {
  
  # adjust probability floor and ceiling
  prob_agent <- case_when(prob_agent >= 1 ~ 1,
                          prob_agent <= 0 ~ 0,
                          TRUE ~ prob_agent)
  
  # add error to probability
  prob_agent <- ifelse(prob_agent > 0.5, prob_agent - prob_error, prob_agent + prob_error)
  
  return(prob_agent)
}



# define function for sampling answers
agent_decision <- function(prob_correct) {
  
  # sample answer according to probability of correct answer
  answer <- sample(c(0, 1), 1, prob = c((1 - prob_correct), prob_correct))
  
  return(answer)
}



# define group_decision function
group_decision <- function(a1_answer, a2_answer, a3_answer, a1_prob, a2_prob, a3_prob) {
  
  # sample answer from groups possible answers
  answer <- sample(c(a1_answer, a2_answer, a3_answer),
                   prob = c(a1_prob, a2_prob, a3_prob),
                   size = 1)
  
  return(answer)
  
}

```



``` {r Simulation Function}

# define function for running simulation
run_simulation <- function(data, n_trials, difficulty_mu, difficulty_sd, prob_error) {
  
  # setup simulation parameters
  difficulty <- rnorm(n_trials, mean = difficulty_mu, sd=difficulty_sd)
  
  # create new dataframe for storing results
  sim_results <- data[, c(1, 2, 5, 9)]  # TODO: Change this to column names for readability
  
  diff_vec <- c()
  mean_vec <- c()
  # running the trials
  for (trial in 1:n_trials) {
    
    # setup colnames depending on trial
    col_difficulty   <- paste('difficulty_t',   trial, sep = '')
    col_prob_correct <- paste('prob_correct_t', trial, sep = '')
    col_agent_answer <- paste('agent_answer_t', trial, sep = '')
    col_group_answer <- paste('group_answer_t', trial, sep = '')
    
    # save difficulty
    sim_results[[col_difficulty]] <- difficulty[trial]
    
    # calculate agent probability of getting a correct response and the actual response
    sim_results[[col_prob_correct]] <- lapply(sim_results$knowledge_scaled * sim_results[[col_difficulty]],
                                              FUN = agent_prob_adjust,
                                              prob_error = prob_error)
    
    sim_results[[col_agent_answer]] <- lapply(sim_results[[col_prob_correct]],
                                              FUN = agent_decision)
    
    # convert to proper data types
    sim_results[[col_prob_correct]] <- as.numeric(sim_results[[col_prob_correct]])
    sim_results[[col_agent_answer]] <- as.integer(sim_results[[col_agent_answer]])
    
    # select group decision
    sim_results <- sim_results %>% 
      group_by(group_id) %>% 
      mutate(!!col_group_answer := group_decision(a1_answer = get(col_agent_answer)[1],
                                                  a2_answer = get(col_agent_answer)[2],
                                                  a3_answer = get(col_agent_answer)[3],
                                                  a1_prob   = conf_group_prob[1],
                                                  a2_prob   = conf_group_prob[2],
                                                  a3_prob   = conf_group_prob[3]))
    
    # saving of mean scores to print
    diff_vec <- append(diff_vec, difficulty[trial])
    mean_vec <- append(mean_vec, mean(sim_results[[col_group_answer]]))
    
  }
  
  # print the stats
  message(paste('AVG Difficulty: ', mean(diff_vec)))
  message(paste('AVG Correct:    ', mean(mean_vec)))
  
  return(sim_results)
}


```



``` {r Simulation}

# running the simulation
sim_results <- run_simulation(data = agent_attr,
                              n_trials = 100,
                              difficulty_mu = 1,
                              difficulty_sd = 0.2,
                              prob_error = 0.02)


```














